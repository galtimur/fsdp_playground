training:
  model_name: "meta-llama/Llama-3.1-8B"
  # "meta-llama/Llama-3.2-3B"
  batch_size: 1
  test_batch_size: 10
  epochs: 1
  lr: 0.0001
  gamma: 0.7
  no_cuda: False
  seed: 1
  save_model: False